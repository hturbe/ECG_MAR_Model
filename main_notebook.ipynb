{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/hturbe/ECG_MAR_Model/blob/main/main_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG classification using MAR coefficients\n",
    "The notebook belows trains a LightGBM model on the disease of interest. There is the possibility to perform an hyperparameter search as well as specifying custom parameters for the model. In the second part of the notebook, interpretability of the model is presented using the Shap framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evironement setup\n",
    "The lines below clone the github repository if the notebook is run in google colab, install requirements as well as downloand the raw data and unzip them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re clone git to acess all scripts if run from google Colab as well as install dependence\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  !git clone https://github.com/hturbe/ECG_MAR_Model.git\n",
    "  !rm ECG_MAR_Model/main_notebook.ipynb\n",
    "  !mv  ECG_MAR_Model/* .\n",
    "  !rm -r ECG_MAR_Model\n",
    "\n",
    "  # Install requirements: \n",
    "  !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unzip data\n",
    "!mkdir data\n",
    "!wget -O data/PhysioNetChallenge2020_Training_CPSC.zip https://sandbox.zenodo.org/record/1036220/files/PhysioNetChallenge2020_Training_CPSC.zip?download=1  \n",
    "!unzip -qo data/PhysioNetChallenge2020_Training_CPSC.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, accuracy_score,\n",
    "                             classification_report, confusion_matrix,\n",
    "                             mean_squared_error)\n",
    "from sklearn.model_selection import KFold  # for K-fold cross validation\n",
    "from sklearn.model_selection import cross_validate  # score evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()\n",
    "\n",
    "CWD = os.getcwd()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "The python file `__exec_data_processing.py` should be run before launching this notebook in order to generate the required data\n",
    "uncomment the cell below to run the full preprocessing pipeline\n",
    "It will take a bit of time to extract the signal from the petastorm file (~ 10 minutes)\n",
    "The permutation test will also take 10 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To run both the preprocessing and the permutation test, uncomment the following cell\n",
    "# %run __exec_data_processing.py --operations extract_signal compute_permutation\n",
    "\n",
    "# To run only the preprocessing  uncomment the following cell\n",
    "%run  __exec_data_processing.py --operations extract_signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select disease of interest\n",
    "The cell below is used to select the disease of interest. Should be one of [lbbb,rbbb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_interest = \"lbbb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_names = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "array_names = []\n",
    "for i in range(len(signal_names)):\n",
    "    for j in range(len(signal_names)):\n",
    "            # array_names.append('X'+signal_names[j] + '-Y' + signal_names[i])\n",
    "            array_names.append(signal_names[j] + '-' + signal_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_coeff = os.path.join(CWD, 'data',\"coeff_matrices\")\n",
    "X_normal  = np.load(os.path.join(path_coeff,'coeff_normal.npy'))\n",
    "y_normal = np.zeros(X_normal.shape[0])\n",
    "print(\"Number of ECGs without disease\", X_normal.shape[0])\n",
    "\n",
    "X_disease = np.load(os.path.join(path_coeff,f\"coeff_{disease_interest}.npy\"))\n",
    "y_disease = np.ones(X_disease.shape[0])\n",
    "print(f\"Number of ECGs with {disease_interest}\", X_disease.shape[0])\n",
    "\n",
    "X_all = np.concatenate((X_normal, X_disease), axis=0)\n",
    "X_all = X_all.reshape(X_all.shape[0], -1)\n",
    "y_all = np.concatenate((y_normal, y_disease), axis=0)\n",
    "\n",
    "df_all = pd.DataFrame(X_all, columns=array_names)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_all, y_all, test_size=0.1, \n",
    "                                                    \n",
    "                                                   )\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "d_test = lgb.Dataset(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To train model with weighted loss\n",
    "weights_y = y_all.shape[0]/y_all.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LightGBM tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model using user-specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_bin\": 512,\n",
    "    \"learning_rate\": 0.12,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"binary_logloss\",\n",
    "    \"num_leaves\": 1420,\n",
    "    \"max_depth\": 4,\n",
    "    \"boost_from_average\": True,\n",
    "    # \"class_weight\" : {1: weights_y, 0: 1}, #To train model with weighted loss\n",
    "    'is_unbalance':True,\n",
    "}\n",
    "metric_scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    **params\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "accuracy=accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "kfold = KFold(n_splits=10, shuffle = True) # k=10 splits the data into 10 equal parts\n",
    "cv_result = cross_validate(lgb.LGBMClassifier(**params),X_all, y_all, cv = 10, scoring = [\"accuracy\", \"precision\", \"recall\", \"f1\"])\n",
    "\n",
    "score_mean = {x:cv_result[x].mean() for x in cv_result.keys()}\n",
    "print(\"Cross-validation metrics: \\n\", os.linesep.join(f\"{x}: {score_mean[x]}\" for x in score_mean.keys()))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, pd.Series(y_pred).round() )\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             )\n",
    "disp.plot() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Hyperparameters optimisation \n",
    "Uncomment the lines in the cell below if you would like to perform hyperparameters optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = { 'max_depth': [3,6,10,20],\n",
    "           'learning_rate': [0.005,0.01, 0.05],\n",
    "           \"max_bin\": [128,256,512],\n",
    "           \"num_leaves\": [50,50,100],\n",
    "           \"num_leaves\": 2000,\n",
    "         \"max_depth\": 6,\n",
    "            }\n",
    "xgbr =lgb.LGBMClassifier(seed = 20, objective= \"binary\",\n",
    "        metric= \"binary_logloss\",)\n",
    "clf = GridSearchCV(estimator=xgbr, \n",
    "                   param_grid=params,\n",
    "                   scoring='accuracy', \n",
    "                   verbose=1,\n",
    "                   n_jobs=4,)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (clf.best_score_))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pd.Series(y_pred).round() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(clf).shap_values(df_all)\n",
    "shap.summary_plot(shap_values[1], df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_interest = \"V1-aVR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,10))\n",
    "shap.dependence_plot(lead_interest, shap_values[1], df_all, interaction_index=None,ax = ax, show=False)\n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f\"shap_{lead_interest}.png\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e02cfc74ff892b8dfd6e5ea53fc3e9732274060ea850b3b8f290cce6e811bf22"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ecg_dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
